{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import jpholiday\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 作業ディレクトリの設定\n",
    "try:\n",
    "    os.chdir('H:/マイドライブ/03_code_test/clustering-house_trial')\n",
    "    data_path_header = 'G:/マイドライブ/01_研究/02_円山町/1_データ前処理'\n",
    "except FileNotFoundError:\n",
    "    os.chdir('G:/マイドライブ/03_code_test/clustering-house_trial')\n",
    "    data_path_header = 'H:/マイドライブ/01_研究/02_円山町/1_データ前処理'\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "\n",
    "# カスタムライブラリのパスを追加\n",
    "sys.path.append(data_path_header)\n",
    "from column_translation import column_translation_dict\n",
    "\n",
    "col_name_dict = {\n",
    "    \"electric\": \"ED\",\n",
    "    \"LD\": \"LD\",\n",
    "    \"kitchen\": \"KT\",\n",
    "    \"bedroom\": \"bed\",\n",
    "    \"bathroom\": \"bath\",\n",
    "    \"washing\": \"WM\",\n",
    "    \"dishwasher\": \"DW\"\n",
    "}\n",
    "\n",
    "def get_household_size(house_num):\n",
    "    num_household_dict = {\n",
    "        80\t: 3,\n",
    "        81\t: 6,\n",
    "        82\t: 3,\n",
    "        83\t: 4,\n",
    "        115\t: 3,\n",
    "        117\t: 4,\n",
    "        118\t: 4,\n",
    "        120\t: 3,\n",
    "        121\t: 2,\n",
    "        124\t: 4,\n",
    "        125\t: 4,\n",
    "        126\t: 3,\n",
    "        127\t: 3,\n",
    "        147\t: 4,\n",
    "        148\t: 4,\n",
    "        150\t: 4,\n",
    "        152\t: 6,\n",
    "        155\t: 5,\n",
    "        156\t: 3,\n",
    "        157\t: 2,\n",
    "        84\t: 4,\n",
    "        92\t: 4,\n",
    "        94\t: 4,\n",
    "        116\t: 4,\n",
    "        119\t: 4,\n",
    "        149\t: 2,\n",
    "        154\t: 4,\n",
    "        158\t: 3,\n",
    "        160\t: 3,\n",
    "        171\t: 3,\n",
    "        172\t: 4,\n",
    "    }\n",
    "    return num_household_dict.get(house_num, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b515182",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('./output_feature/80_LD_energy_metrics.csv')\n",
    "\n",
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86730335",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['month', 'weekday_weekend_ratio',\n",
    "                 'act-pro_0-6', 'act-pro_6-12', 'act-pro_12-18', 'act-pro_18-24',\n",
    "                 'time_bin_0-6', 'time_bin_6-12', 'time_bin_12-18', 'time_bin_18-24']\n",
    "\n",
    "csv_path_list = glob.glob('./output_feature/*.csv')\n",
    "\n",
    "# ファイル名の先頭2文字を取り出して集合化\n",
    "prefixes = {int(os.path.basename(p).split('_')[0]) for p in csv_path_list}\n",
    "house_num_list = sorted(prefixes)\n",
    "house_num_list = [80, 81, 82, 83, 115, 117, 118, 120, 121, 124, 125, 147, 148, 150, 152, 155, 156, 157]\n",
    "print(house_num_list, len(house_num_list))\n",
    "\n",
    "df_data = pd.DataFrame()\n",
    "for house_num in house_num_list:\n",
    "    csv_path_list = glob.glob(f'./output_feature/{house_num}_*.csv')\n",
    "    csv_path_list.sort()\n",
    "    df_data_house = pd.DataFrame()\n",
    "    for csv_path in csv_path_list:\n",
    "        df_temp = pd.read_csv(csv_path)\n",
    "        df_temp = df_temp[features_list]\n",
    "        col_name = os.path.basename(csv_path).split('_')[1].replace('.csv', '')\n",
    "        col_name = col_name_dict.get(col_name, col_name)\n",
    "        df_temp.columns = [f'{col_name}_{col}' if col != 'month' else col for col in df_temp.columns]\n",
    "        df_data_house = pd.merge(df_data_house, df_temp, on='month') if not df_data_house.empty else df_temp\n",
    "    df_data_house['household_size'] = get_household_size(house_num)\n",
    "    df_data_house['house_id'] = house_num\n",
    "    df_data = pd.concat([df_data, df_data_house], axis=0).reset_index(drop=True)\n",
    "\n",
    "# print(df_data.head(5))\n",
    "print(df_data.shape)\n",
    "\n",
    "# 欠損処理\n",
    "df_dropped = df_data.drop(['month', 'house_id'], axis=1)\n",
    "df_dropped = df_dropped.replace([np.inf, -np.inf], np.nan).astype(\"float64\")\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X = imp.fit_transform(df_dropped)\n",
    "clean_imputed = pd.DataFrame(X, columns=df_dropped.columns, index=df_dropped.index)\n",
    "df_features = clean_imputed\n",
    "# 正規化\n",
    "mm = preprocessing.MinMaxScaler()\n",
    "df_features_mm = pd.DataFrame(mm.fit_transform(df_features), columns=df_features.columns)\n",
    "\n",
    "# print(df_features_mm.head(5))\n",
    "print(df_features_mm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d425295",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_features_mm.shape[0] / df_features_mm.shape[1] < 2:\n",
    "    print(\"サンプル数が少ないため、PCAで次元削減を実施\")\n",
    "    # PCAで次元削減\n",
    "    n_pca_components = df_features_mm.shape[0]/2.5  # サンプル数や特徴量数に応じて調整\n",
    "    pca = PCA(n_components=n_pca_components, random_state=42)\n",
    "    df_features_pca = pca.fit_transform(df_features_mm)\n",
    "    df_features_mm = df_features_pca\n",
    "else:\n",
    "    print(\"サンプル数が十分にあるため、次元削減は実施しない\")\n",
    "\n",
    "# =========================\n",
    "# エルボー法\n",
    "inertia = []\n",
    "K_range = range(1, 27)  # 1〜14クラスタで確認\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_features_mm)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia (SSE)\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.grid(True)\n",
    "\n",
    "# =========================\n",
    "# シルエット分析\n",
    "sil_scores = []\n",
    "K_range_sil = range(2, 27)  # シルエットスコアはk>=2\n",
    "for k in K_range_sil:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(df_features_mm)\n",
    "    score = silhouette_score(df_features_mm, labels)\n",
    "    sil_scores.append(score)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range_sil, sil_scores, marker='o')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Analysis\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 推奨kの候補表示\n",
    "best_sil_idx = sil_scores.index(max(sil_scores))\n",
    "recommended_k = K_range_sil[best_sil_idx]\n",
    "print(f\"シルエットスコア最大のkの候補: {recommended_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---kmeans clusters---')\n",
    "k = 8 # クラスター数を指示\n",
    "kmeanModel = KMeans(n_clusters=k, random_state=42)\n",
    "kmeanModel.fit(df_features_mm)\n",
    "clusters_kmeans = kmeanModel.labels_\n",
    "# クラスターごとに何サンプルあるか\n",
    "for i in range(k):\n",
    "    num = list(clusters_kmeans).count(i)\n",
    "    print(f'Cluster {i}: n = {num}')\n",
    "\n",
    "list_clusters_kmeans = list(set(clusters_kmeans))\n",
    "colors_kmeans = plt.cm.get_cmap(\"hsv\", len(list_clusters_kmeans))\n",
    "print(list_clusters_kmeans, len(list_clusters_kmeans))\n",
    "\n",
    "print('---house clusters---')\n",
    "clusters_str = df_data['house_id'].astype(str)\n",
    "le = LabelEncoder()\n",
    "clusters_house = le.fit_transform(clusters_str)\n",
    "list_clusters_house = list(set(le.classes_))\n",
    "colors_house = plt.cm.get_cmap(\"hsv\", len(list_clusters_house))\n",
    "print(list_clusters_house, len(list_clusters_house))\n",
    "\n",
    "print('---month clusters---')\n",
    "clusters_str = df_data['month'].astype(str)\n",
    "le = LabelEncoder()\n",
    "clusters_month = le.fit_transform(clusters_str)\n",
    "list_clusters_month = list(set(le.classes_))\n",
    "colors_month = plt.cm.get_cmap(\"hsv\", len(list_clusters_month))\n",
    "print(list_clusters_month, len(list_clusters_month))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(df_features_mm)\n",
    "score = pd.DataFrame(pca.transform(df_features_mm))#, index=df_features.index)\n",
    "# pca.explained_variance_ratio_\n",
    "\n",
    "plt.scatter(score.iloc[:,0], score.iloc[:,1],\n",
    "            c=clusters_kmeans, cmap=colors_kmeans, alpha=0.7)\n",
    "plt.title('PCA plot(kmeans)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(score.iloc[:,0], score.iloc[:,1],\n",
    "            c=clusters_house, cmap=colors_house, alpha=0.7)\n",
    "plt.title('PCA plot(house)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plt.scatter(score.iloc[:,0], score.iloc[:,1],\n",
    "#             c=clusters_month, cmap=colors_month, alpha=0.7)\n",
    "# plt.title('PCA plot(month)')\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_performance = pd.DataFrame()\n",
    "# 寄与率\n",
    "CEVR = pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(len(df_features.columns))], columns=[\"CEVR\"])\n",
    "# 固有値\n",
    "Eigenvalue = pd.DataFrame(pca.explained_variance_, index=[\"PC{}\".format(x + 1) for x in range(len(df_features.columns))], columns=[\"Eigenvalue\"])\n",
    "# 固有ベクトル\n",
    "Eigenvector = pd.DataFrame(pca.components_, columns=df_features.columns, index=[\"PC{}\".format(x + 1) for x in range(len(df_features.columns))])\n",
    "\n",
    "df_pca_performance = pd.concat([CEVR, Eigenvalue, Eigenvector], axis=1)\n",
    "\n",
    "print(df_pca_performance)\n",
    "\n",
    "# 累積寄与率を図示する\n",
    "import matplotlib.ticker as ticker\n",
    "plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "plt.plot([0] + list( np.cumsum(pca.explained_variance_ratio_)), \"-o\")\n",
    "plt.xlabel(\"Number of principal components\")\n",
    "plt.ylabel(\"Cumulative contribution rate\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 第一主成分と第二主成分における観測変数の寄与度をプロットする\n",
    "plt.figure(figsize=(6, 6))\n",
    "for x, y, name in zip(pca.components_[0], pca.components_[1], df_features_mm.columns):\n",
    "    plt.text(x, y, name)\n",
    "plt.scatter(pca.components_[0], pca.components_[1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embedding = TSNE(random_state=42).fit_transform(df_features_mm)\n",
    "\n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "#     c=clusters_kmeans, cmap=colors_kmeans, alpha=0.7)\n",
    "# plt.title('t-SNE plot(kmeans)')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "#     c=clusters_house, cmap=colors_house, alpha=0.7)\n",
    "# plt.title('t-SNE plot(house)')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "#     c=clusters_month, cmap=colors_month, alpha=0.7)\n",
    "# plt.title('t-SNE plot(month)')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapper = umap.UMAP(random_state=42)\n",
    "embedding = mapper.fit_transform(df_features_mm)\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "    c=clusters_kmeans, cmap=colors_kmeans, alpha=0.7)\n",
    "plt.title('UMAP plot(kmeans)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "    c=clusters_house, cmap=colors_house, alpha=0.7)\n",
    "plt.title('UMAP plot(house)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "    c=clusters_month, cmap=colors_month, alpha=0.7)\n",
    "plt.title('UMAP plot(month)')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = len(df_features.columns)\n",
    "# cols = 5\n",
    "# rows = math.ceil(N / cols)\n",
    "\n",
    "# fig = plt.figure(figsize=(3*cols,3*rows))\n",
    "# features_cols = df_features.columns\n",
    "\n",
    "# for i, col in enumerate(features_cols):\n",
    "#     ax = fig.add_subplot(rows, cols, i+1, title=col)\n",
    "#     ax.scatter(embedding[:, 0], embedding[:, 1],\n",
    "#         c=df_features[col], cmap='plasma', alpha=0.8)\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clusters = clusters_kmeans\n",
    "list_clusters = list_clusters_kmeans\n",
    "\n",
    "df_features_with_clusters = df_features.copy()\n",
    "df_features_with_clusters['cluster'] = clusters\n",
    "features_cols = df_features.columns\n",
    "\n",
    "# 閾値を定める。ここでは補正後のp値 (q値) が0.05以下かつ数値の比 (Fold Change:fc)が2倍以上あるか、を閾値とします。\n",
    "q_threshold = 0.05\n",
    "fc_threshold = 2\n",
    "\n",
    "import math\n",
    "N = len(set(clusters))\n",
    "cols = 3\n",
    "rows = math.ceil(N / cols)\n",
    "fig = plt.figure(figsize=(4*cols, 4*rows))\n",
    "# クラスターごとに評価する\n",
    "for i in range(len(set(clusters))):\n",
    "    p_values = []\n",
    "    fcs = []\n",
    "    # 変数 = プロット上の1点\n",
    "    for col in features_cols:\n",
    "        # 検定\n",
    "        group_1 = df_features_with_clusters[df_features_with_clusters['cluster'] == i][col]\n",
    "        group_2 = df_features_with_clusters[df_features_with_clusters['cluster'] != i][col]\n",
    "        p_value = stats.ttest_ind(group_1, group_2, equal_var=False)[1]\n",
    "        p_values.append(p_value)\n",
    "\n",
    "        # Fold change. 平均での比較が不適切であればここをmedian等に変える\n",
    "        fc = group_1.mean()/group_2.mean()\n",
    "        fcs.append(fc)\n",
    "\n",
    "    # p-valueの補正\n",
    "    q_values = multipletests(p_values, method='fdr_bh')[1]\n",
    "\n",
    "    # 閾値を超えたものは色を変える\n",
    "    colors = []\n",
    "    for col, q_value, fc in zip(features_cols, q_values, fcs):\n",
    "        # 対象がその他の2倍大きいときはオレンジ\n",
    "        if q_value < q_threshold and fc > fc_threshold:\n",
    "            colors.append('orange')\n",
    "        # その他が対象の2倍大きいときは水色\n",
    "        elif q_value < q_threshold and fc < 1/fc_threshold:\n",
    "            colors.append('skyblue')\n",
    "        # 大きな違いがない場合は灰色\n",
    "        else:\n",
    "            colors.append('gray')\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i+1)\n",
    "    ax.scatter(np.log2(fcs), -np.log10(q_values),\n",
    "    c=colors)\n",
    "\n",
    "    # 図をきれいに見せるためのあれこれ。好みの世界\n",
    "    max_val = max(abs(np.nanmin(np.log2(fcs)[np.log2(fcs) != -np.inf])), max(np.log2(fcs)))\n",
    "    ax.set_xlim([-max_val-1, max_val+1]) # -infがあるので。-inf = そのクラスターでは全員が0\n",
    "    ax.set_ylim(ax.get_ylim())\n",
    "    # 閾値に点線をつける\n",
    "    ax.hlines([-np.log10(q_threshold)], -max_val-1, max_val+1, 'gray', 'dashed', linewidth=0.5, alpha=0.5)\n",
    "    ax.vlines([np.log2(fc_threshold), np.log2(1/fc_threshold)], ax.get_ylim()[0], ax.get_ylim()[1], 'gray', 'dashed', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # ラベルとアノテーション\n",
    "    ax.set_title(f'{list_clusters[i]}')\n",
    "    ax.set_xlabel('logFC')\n",
    "    ax.set_ylabel('-log10(q-values)')\n",
    "    for j, label in enumerate(features_cols):\n",
    "        if colors[j] in ['orange', 'skyblue']:\n",
    "            ax.annotate(label, (np.log2(fcs)[j], -np.log10(q_values)[j]), size=9)\n",
    "\n",
    "\n",
    "# fig.suptitle('Volcano plots')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_features_mm.columns\n",
    "\n",
    "cols = ['LD_act-pro_0-6', 'LD_act-pro_6-12', 'LD_act-pro_12-18', 'LD_act-pro_18-24',\n",
    "'bath_act-pro_0-6', 'bath_act-pro_6-12', 'bath_act-pro_12-18', 'bath_act-pro_18-24',\n",
    "'bed_act-pro_0-6', 'bed_act-pro_6-12', 'bed_act-pro_12-18', 'bed_act-pro_18-24',\n",
    "'DW_act-pro_0-6', 'DW_act-pro_6-12', 'DW_act-pro_12-18', 'DW_act-pro_18-24',\n",
    "'KT_act-pro_0-6', 'KT_act-pro_6-12', 'KT_act-pro_12-18', 'KT_act-pro_18-24',\n",
    "'WM_act-pro_0-6', 'WM_act-pro_6-12', 'WM_act-pro_12-18', 'WM_act-pro_18-24',]\n",
    "\n",
    "replace_map = {\n",
    "    \"act-pro\": \"act\",\n",
    "    \"time_bin\": \"consumption\",\n",
    "}\n",
    "def replace_multi(s):\n",
    "    for old, new in replace_map.items():\n",
    "        s = s.replace(old, new)\n",
    "    return s\n",
    "plot_cols = [replace_multi(col) for col in cols]\n",
    "\n",
    "df_features_mm_clusters = df_features_mm.copy()\n",
    "df_features_mm_clusters['cluster'] = clusters_kmeans\n",
    "labels = [f'{i}' for i in range(k)]\n",
    "x = []\n",
    "y = []\n",
    "targets = []\n",
    "colors = []\n",
    "for i, col in enumerate(cols):\n",
    "    for j, cluster_name in enumerate(clusters_kmeans):\n",
    "        target_value = df_features_mm_clusters[df_features_mm_clusters['cluster']==j][col].mean()\n",
    "        x.append(j)\n",
    "        y.append(i)\n",
    "        targets.append(np.exp(1+target_value*4)) # ここはVolcano plotsを見ながら調整\n",
    "plt.figure(figsize=(4, 7))\n",
    "plt.scatter(x, y, s=targets, c=targets, cmap='plasma')\n",
    "plt.xticks(list(range(k)), labels, fontsize=14)\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.yticks(list(range(len(cols))), plot_cols, fontsize=14)\n",
    "plt.tick_params(axis='y', which='major', pad=6)\n",
    "# --- 4行ごとに横線を引く ---\n",
    "for yline in range(4, len(cols), 4):\n",
    "    plt.axhline(y=yline - 0.5, color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umapfix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
